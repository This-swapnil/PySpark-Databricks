{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LEAD AND LAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/22 22:02:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/22 22:02:26 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Windows_Functions_Lead_Lag\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        James|     Sales|  3000|\n",
      "|         Saif|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        scott|   Finance|  3000|\n",
      "|          Jen| Marketing|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = (\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Saif\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"scott\", \"Finance\", 3000),\n",
    "    (\"Jen\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    ")\n",
    "columns = [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAG Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|employee_name|department|salary| lag|\n",
      "+-------------+----------+------+----+\n",
      "|        Maria|   Finance|  3000|NULL|\n",
      "|        scott|   Finance|  3000|3000|\n",
      "|        Kumar| Marketing|  2000|NULL|\n",
      "|          Jen| Marketing|  3000|2000|\n",
      "|        James|     Sales|  3000|NULL|\n",
      "|        James|     Sales|  3000|3000|\n",
      "|       Robert|     Sales|  4100|3000|\n",
      "|         Saif|     Sales|  4100|4100|\n",
      "|      Michael|     Sales|  4600|4100|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"lag\", lag(\"salary\", 1).over(window=windowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LEAD window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|employee_name|department|salary|lead|\n",
      "+-------------+----------+------+----+\n",
      "|        Maria|   Finance|  3000|3000|\n",
      "|        scott|   Finance|  3000|NULL|\n",
      "|        Kumar| Marketing|  2000|3000|\n",
      "|          Jen| Marketing|  3000|NULL|\n",
      "|        James|     Sales|  3000|3000|\n",
      "|        James|     Sales|  3000|4100|\n",
      "|       Robert|     Sales|  4100|4100|\n",
      "|         Saif|     Sales|  4100|4600|\n",
      "|      Michael|     Sales|  4600|NULL|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"lead\", lead(\"salary\", 1).over(window=windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
