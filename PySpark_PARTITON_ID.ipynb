{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/22 15:13:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/22 15:13:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/02/22 15:13:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/02/22 15:13:54 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"PySpark_Dataframe_Insert_into_Spark_table\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+---+-----+\n",
      "|Year|First Name|     County|Sex|Count|\n",
      "+----+----------+-----------+---+-----+\n",
      "|2007|      ZOEY|      KINGS|  F|   11|\n",
      "|2007|      ZOEY|    SUFFOLK|  F|    6|\n",
      "|2007|      ZOEY|     MONROE|  F|    6|\n",
      "|2007|      ZOEY|       ERIE|  F|    9|\n",
      "|2007|       ZOE|     ULSTER|  F|    5|\n",
      "|2007|       ZOE|WESTCHESTER|  F|   24|\n",
      "|2007|       ZOE|      BRONX|  F|   13|\n",
      "|2007|       ZOE|   NEW YORK|  F|   55|\n",
      "|2007|       ZOE|     NASSAU|  F|   15|\n",
      "|2007|       ZOE|       ERIE|  F|    6|\n",
      "|2007|       ZOE|    SUFFOLK|  F|   14|\n",
      "|2007|       ZOE|      KINGS|  F|   34|\n",
      "|2007|       ZOE|     MONROE|  F|    9|\n",
      "|2007|       ZOE|     QUEENS|  F|   26|\n",
      "|2007|       ZOE|     ALBANY|  F|    5|\n",
      "|2007|     ZISSY|   ROCKLAND|  F|    5|\n",
      "|2007|     ZISSY|      KINGS|  F|   27|\n",
      "|2007|      ZION|      KINGS|  M|   15|\n",
      "|2007|      ZION|      BRONX|  M|   14|\n",
      "|2007|       ZEV|   ROCKLAND|  M|    6|\n",
      "+----+----------+-----------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.option(\"sep\", \",\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"Baby_Names.csv\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import spark_partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+---+-----+-----------+\n",
      "|Year|First Name|County     |Sex|Count|partitionId|\n",
      "+----+----------+-----------+---+-----+-----------+\n",
      "|2007|ZOEY      |KINGS      |F  |11   |0          |\n",
      "|2007|ZOEY      |SUFFOLK    |F  |6    |0          |\n",
      "|2007|ZOEY      |MONROE     |F  |6    |0          |\n",
      "|2007|ZOEY      |ERIE       |F  |9    |0          |\n",
      "|2007|ZOE       |ULSTER     |F  |5    |0          |\n",
      "|2007|ZOE       |WESTCHESTER|F  |24   |0          |\n",
      "|2007|ZOE       |BRONX      |F  |13   |0          |\n",
      "|2007|ZOE       |NEW YORK   |F  |55   |0          |\n",
      "|2007|ZOE       |NASSAU     |F  |15   |0          |\n",
      "|2007|ZOE       |ERIE       |F  |6    |0          |\n",
      "|2007|ZOE       |SUFFOLK    |F  |14   |0          |\n",
      "|2007|ZOE       |KINGS      |F  |34   |0          |\n",
      "|2007|ZOE       |MONROE     |F  |9    |0          |\n",
      "|2007|ZOE       |QUEENS     |F  |26   |0          |\n",
      "|2007|ZOE       |ALBANY     |F  |5    |0          |\n",
      "|2007|ZISSY     |ROCKLAND   |F  |5    |0          |\n",
      "|2007|ZISSY     |KINGS      |F  |27   |0          |\n",
      "|2007|ZION      |KINGS      |M  |15   |0          |\n",
      "|2007|ZION      |BRONX      |M  |14   |0          |\n",
      "|2007|ZEV       |ROCKLAND   |M  |6    |0          |\n",
      "+----+----------+-----------+---+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn(\"partitionId\", spark_partition_id())\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+---+-----+\n",
      "|Year|First Name|County     |Sex|Count|\n",
      "+----+----------+-----------+---+-----+\n",
      "|2007|ZOEY      |KINGS      |F  |11   |\n",
      "|2007|ZOEY      |SUFFOLK    |F  |6    |\n",
      "|2007|ZOEY      |MONROE     |F  |6    |\n",
      "|2007|ZOEY      |ERIE       |F  |9    |\n",
      "|2007|ZOE       |ULSTER     |F  |5    |\n",
      "|2007|ZOE       |WESTCHESTER|F  |24   |\n",
      "|2007|ZOE       |BRONX      |F  |13   |\n",
      "|2007|ZOE       |NEW YORK   |F  |55   |\n",
      "|2007|ZOE       |NASSAU     |F  |15   |\n",
      "|2007|ZOE       |ERIE       |F  |6    |\n",
      "|2007|ZOE       |SUFFOLK    |F  |14   |\n",
      "|2007|ZOE       |KINGS      |F  |34   |\n",
      "|2007|ZOE       |MONROE     |F  |9    |\n",
      "|2007|ZOE       |QUEENS     |F  |26   |\n",
      "|2007|ZOE       |ALBANY     |F  |5    |\n",
      "|2007|ZISSY     |ROCKLAND   |F  |5    |\n",
      "|2007|ZISSY     |KINGS      |F  |27   |\n",
      "|2007|ZION      |KINGS      |M  |15   |\n",
      "|2007|ZION      |BRONX      |M  |14   |\n",
      "|2007|ZEV       |ROCKLAND   |M  |6    |\n",
      "+----+----------+-----------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.repartition(10).withColumn(\"partitionId\", spark_partition_id())\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|partitionId|count|\n",
      "+-----------+-----+\n",
      "|          0| 5226|\n",
      "|          9| 5226|\n",
      "|          1| 5225|\n",
      "|          2| 5225|\n",
      "|          3| 5225|\n",
      "|          4| 5225|\n",
      "|          5| 5225|\n",
      "|          6| 5225|\n",
      "|          7| 5225|\n",
      "|          8| 5225|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy by partitionId\n",
    "from pyspark.sql.functions import spark_partition_id, asc, desc\n",
    "\n",
    "df3 = (\n",
    "    df2.withColumn(\"partitionId\", spark_partition_id())\n",
    "    .groupBy(\"partitionId\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+------+-----+-----------------+\n",
      "|summary|Year              |First Name|County|Sex  |Count            |\n",
      "+-------+------------------+----------+------+-----+-----------------+\n",
      "|count  |52252             |52252     |52252 |52252|52252            |\n",
      "|mean   |2010.6141583097299|NULL      |NULL  |NULL |18.05534716374493|\n",
      "|stddev |2.355530993500322 |NULL      |NULL  |NULL |22.67625097645675|\n",
      "|min    |2007              |AADEN     |ALBANY|F    |5                |\n",
      "|max    |2014              |ZURI      |YATES |M    |297              |\n",
      "+-------+------------------+----------+------+-----+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
