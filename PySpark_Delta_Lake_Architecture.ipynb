{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Internal Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/nil/anaconda3/envs/spark/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/nil/.ivy2/cache\n",
      "The jars for the packages stored in: /home/nil/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-978a1ab7-5a0f-4559-bbfc-aa63d3822b2e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in central\n",
      "\tfound io.delta#delta-storage;3.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 358ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-978a1ab7-5a0f-4559-bbfc-aa63d3822b2e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/7ms)\n",
      "24/02/16 11:35:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/16 11:36:11 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder.appName(\"MyApp\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\n",
    "        \"spark.sql.catalog.spark_catalog\",\n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "    )\n",
    ")\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<delta.tables.DeltaTable at 0x7f58a1e98dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.create(spark).tableName(\"delta_internal_table_01\").addColumn(\n",
    "    \"emp_id\", \"INT\"\n",
    ").addColumn(\"emp_name\", \"STRING\").addColumn(\"gender\", \"STRING\").addColumn(\n",
    "    \"salary\", \"INT\"\n",
    ").addColumn(\n",
    "    \"Dept\", \"STRING\"\n",
    ").property(\n",
    "    \"description\", \"table created for demo purpose\"\n",
    ").location(\n",
    "    \"/mnt/sda3/iNeuron/Data Engineering/pySpark/Delta_Lake/delta_lake_01\"\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+----+\n",
      "|emp_id|emp_name|gender|salary|Dept|\n",
      "+------+--------+------+------+----+\n",
      "+------+--------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(\"./Delta_Lake/delta_lake_01/\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+----+\n",
      "|emp_id|emp_name|gender|salary|Dept|\n",
      "+------+--------+------+------+----+\n",
      "+------+--------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from delta_internal_table_01\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"insert into delta_internal_table_01 values(100,'Stephen','M',2000,'IT')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+----+\n",
      "|emp_id|emp_name|gender|salary|Dept|\n",
      "+------+--------+------+------+----+\n",
      "|   100| Stephen|     M|  2000|  IT|\n",
      "+------+--------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from delta_internal_table_01\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"insert into delta_internal_table_01 values(200,'Philipp','M',8000,'HR'),(300,'Laura','F',6000,'SALES')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+\n",
      "|emp_id|emp_name|gender|salary| Dept|\n",
      "+------+--------+------+------+-----+\n",
      "|   300|   Laura|     F|  6000|SALES|\n",
      "|   200| Philipp|     M|  8000|   HR|\n",
      "|   100| Stephen|     M|  2000|   IT|\n",
      "+------+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from delta_internal_table_01\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+\n",
      "|emp_id|emp_name|gender|salary| Dept|\n",
      "+------+--------+------+------+-----+\n",
      "|   300|   Laura|     F|  6000|SALES|\n",
      "|   200| Philipp|     M|  8000|   HR|\n",
      "+------+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from delta_internal_table_01 where emp_id>100\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+----+\n",
      "|emp_id|emp_name|gender|salary|Dept|\n",
      "+------+--------+------+------+----+\n",
      "|   200| Philipp|     M|  8000|  HR|\n",
      "+------+--------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"parquet\").load(\n",
    "    \"Delta_Lake/delta_lake_01/part-00000-5dd265a0-43e0-4c7c-a820-e7a3bb5e8dda-c000.snappy.parquet\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE delta_internal_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------+-----------+\n",
      "|namespace|tableName              |isTemporary|\n",
      "+---------+-----------------------+-----------+\n",
      "|default  |delta_internal_table_01|false      |\n",
      "+---------+-----------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
